{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PA9q9SvA_gh6iHcnF8_o12Zzh0xeoKGt",
      "authorship_tag": "ABX9TyPY1XVdehbHls7f6PR5L7lx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1j3PkP9yN3K",
        "outputId": "4bd50e55-38b9-4fd2-cbce-4f2eb4777579"
      },
      "source": [
        "!rm -rf sample_data\r\n",
        "!git clone https://www.github.com/harvitronix/five-video-classification-methods.git\r\n",
        "!mv five-video-classification-methods/* .\r\n",
        "!rm -rf five-video-classification-methods"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'five-video-classification-methods'...\n",
            "warning: redirecting to https://github.com/harvitronix/five-video-classification-methods.git/\n",
            "remote: Enumerating objects: 495, done.\u001b[K\n",
            "remote: Total 495 (delta 0), reused 0 (delta 0), pack-reused 495\u001b[K\n",
            "Receiving objects: 100% (495/495), 322.37 KiB | 3.88 MiB/s, done.\n",
            "Resolving deltas: 100% (289/289), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyJYAcHByk4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4584775d-504c-4ee4-ba15-82d5200e238a"
      },
      "source": [
        "!rsync --progress drive/MyDrive/data_tar/test.tar .\r\n",
        "!tar xf test.tar --checkpoint=.5000\r\n",
        "!rm test.tar\r\n",
        "!mv test data\r\n",
        "!echo\r\n",
        "\r\n",
        "!rsync --progress drive/MyDrive/data_tar/train.tar .\r\n",
        "!tar xf train.tar --checkpoint=.10000\r\n",
        "!rm train.tar\r\n",
        "!mv train data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.tar\n",
            "  5,118,146,560 100%   21.20MB/s    0:03:50 (xfr#1, to-chk=0/1)\n",
            "...................................................................................................\n",
            "train.tar\n",
            " 13,107,425,280 100%   18.82MB/s    0:11:04 (xfr#1, to-chk=0/1)\n",
            "................................................................................................................................"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEgVOZuT9Txt"
      },
      "source": [
        "!mkdir data/checkpoints\r\n",
        "!mkdir data/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHa-pJgu9ikv"
      },
      "source": [
        "# replace the csv file with the one from drive\r\n",
        "!mv data/data_file.csv data/data_file_original.csv\r\n",
        "!rsync -progress drive/MyDrive/data/data_file.csv data/data_file.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbWa9I9qhv5x",
        "outputId": "f21855ee-4583-4cdc-fa1d-a6fd17bf3356"
      },
      "source": [
        "# TRAIN CNN\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, CSVLogger\n",
        "from data import DataSet\n",
        "import os.path\n",
        "import time\n",
        "\n",
        "data = DataSet()\n",
        "\n",
        "# Helper: Save the model.\n",
        "checkpointer = ModelCheckpoint(\n",
        "    filepath=os.path.join('data', 'checkpoints', 'inception.{epoch:03d}-{val_loss:.2f}.hdf5'),\n",
        "    verbose=1,\n",
        "    save_best_only=True)\n",
        "\n",
        "# Helper: Stop when we stop learning.\n",
        "early_stopper = EarlyStopping(patience=10)\n",
        "\n",
        "# Helper: TensorBoard\n",
        "tensorboard = TensorBoard(log_dir=os.path.join('data', 'logs'))\n",
        "\n",
        "# Helper: CSV Logger\n",
        "timestamp = time.time()\n",
        "csv_logger = CSVLogger(os.path.join('data', 'logs', 'cnn-training-' + \\\n",
        "        str(timestamp) + '.log'))\n",
        "\n",
        "def get_generators():\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=10.,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2)\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        os.path.join('data', 'train'),\n",
        "        target_size=(299, 299),\n",
        "        batch_size=32,\n",
        "        classes=data.classes,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        os.path.join('data', 'test'),\n",
        "        target_size=(299, 299),\n",
        "        batch_size=32,\n",
        "        classes=data.classes,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "def get_model(weights='imagenet'):\n",
        "    # create the base pre-trained model\n",
        "    base_model = InceptionV3(weights=weights, include_top=False)\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    # and a logistic layer\n",
        "    predictions = Dense(len(data.classes), activation='softmax')(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "def freeze_all_but_top(model):\n",
        "    \"\"\"Used to train just the top layers of the model.\"\"\"\n",
        "    # first: train only the top layers (which were randomly initialized)\n",
        "    # i.e. freeze all convolutional InceptionV3 layers\n",
        "    for layer in model.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # compile the model (should be done *after* setting layers to non-trainable)\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def freeze_all_but_mid_and_top(model):\n",
        "    \"\"\"After we fine-tune the dense layers, train deeper.\"\"\"\n",
        "    # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "    # the first 172 layers and unfreeze the rest:\n",
        "    for layer in model.layers[:172]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[172:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # we need to recompile the model for these modifications to take effect\n",
        "    # we use SGD with a low learning rate\n",
        "    model.compile(\n",
        "        optimizer=SGD(lr=0.0001, momentum=0.9),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, nb_epoch, generators, callbacks=[]):\n",
        "    train_generator, validation_generator = generators\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=100,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=10,\n",
        "        epochs=nb_epoch,\n",
        "        callbacks=callbacks)\n",
        "    return model\n",
        "\n",
        "def main(weights_file):\n",
        "    model = get_model()\n",
        "    generators = get_generators()\n",
        "\n",
        "    if weights_file is None:\n",
        "        print(\"Loading network from ImageNet weights.\")\n",
        "        # Get and train the top layers.\n",
        "        model = freeze_all_but_top(model)\n",
        "        model = train_model(model, 10, generators)\n",
        "    else:\n",
        "        print(\"Loading saved model: %s.\" % weights_file)\n",
        "        model.load_weights(weights_file)\n",
        "\n",
        "    # Get and train the mid layers.\n",
        "    model = freeze_all_but_mid_and_top(model)\n",
        "    model = train_model(model, 1000, generators,\n",
        "                        [checkpointer, early_stopper, tensorboard, csv_logger])\n",
        "\n",
        "main(weights_file=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Found 1788425 images belonging to 101 classes.\n",
            "Found 697865 images belonging to 101 classes.\n",
            "Loading network from ImageNet weights.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 5.3653 - accuracy: 0.1086WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 89s 742ms/step - loss: 5.3521 - accuracy: 0.1094 - val_loss: 2.6312 - val_accuracy: 0.4062\n",
            "Epoch 2/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4937 - accuracy: 0.4033WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 77s 741ms/step - loss: 2.4917 - accuracy: 0.4036 - val_loss: 2.1678 - val_accuracy: 0.4563\n",
            "Epoch 3/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9063 - accuracy: 0.5266WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 82s 751ms/step - loss: 1.9053 - accuracy: 0.5268 - val_loss: 1.6559 - val_accuracy: 0.5312\n",
            "Epoch 4/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5193 - accuracy: 0.5944WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 735ms/step - loss: 1.5193 - accuracy: 0.5943 - val_loss: 1.7825 - val_accuracy: 0.5156\n",
            "Epoch 5/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3758 - accuracy: 0.6272WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 735ms/step - loss: 1.3753 - accuracy: 0.6273 - val_loss: 1.6801 - val_accuracy: 0.5625\n",
            "Epoch 6/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2486 - accuracy: 0.6576WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 743ms/step - loss: 1.2486 - accuracy: 0.6576 - val_loss: 1.7615 - val_accuracy: 0.5469\n",
            "Epoch 7/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2161 - accuracy: 0.6676WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 736ms/step - loss: 1.2160 - accuracy: 0.6676 - val_loss: 1.7308 - val_accuracy: 0.5500\n",
            "Epoch 8/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1287 - accuracy: 0.7055WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 79s 734ms/step - loss: 1.1283 - accuracy: 0.7055 - val_loss: 1.4175 - val_accuracy: 0.6500\n",
            "Epoch 9/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0457 - accuracy: 0.7170WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 740ms/step - loss: 1.0454 - accuracy: 0.7171 - val_loss: 2.0087 - val_accuracy: 0.5188\n",
            "Epoch 10/10\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0145 - accuracy: 0.7271WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 79s 735ms/step - loss: 1.0139 - accuracy: 0.7272 - val_loss: 1.5430 - val_accuracy: 0.5969\n",
            "Epoch 1/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.8892 - accuracy: 0.5133 - top_k_categorical_accuracy: 0.7990WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 90s 812ms/step - loss: 1.8862 - accuracy: 0.5141 - top_k_categorical_accuracy: 0.7994 - val_loss: 1.4156 - val_accuracy: 0.6219 - val_top_k_categorical_accuracy: 0.8562\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.41561, saving model to data/checkpoints/inception.001-1.42.hdf5\n",
            "Epoch 2/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2051 - accuracy: 0.6821 - top_k_categorical_accuracy: 0.8924WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 765ms/step - loss: 1.2044 - accuracy: 0.6823 - top_k_categorical_accuracy: 0.8925 - val_loss: 1.4864 - val_accuracy: 0.6156 - val_top_k_categorical_accuracy: 0.8375\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.41561\n",
            "Epoch 3/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0225 - accuracy: 0.7343 - top_k_categorical_accuracy: 0.9101WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 82s 766ms/step - loss: 1.0222 - accuracy: 0.7344 - top_k_categorical_accuracy: 0.9102 - val_loss: 1.4118 - val_accuracy: 0.6344 - val_top_k_categorical_accuracy: 0.8313\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.41561 to 1.41176, saving model to data/checkpoints/inception.003-1.41.hdf5\n",
            "Epoch 4/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.7624 - top_k_categorical_accuracy: 0.9390WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 79s 760ms/step - loss: 0.8692 - accuracy: 0.7625 - top_k_categorical_accuracy: 0.9390 - val_loss: 1.5117 - val_accuracy: 0.6000 - val_top_k_categorical_accuracy: 0.8406\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.41176\n",
            "Epoch 5/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8951 - accuracy: 0.7684 - top_k_categorical_accuracy: 0.9370WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 83s 771ms/step - loss: 0.8947 - accuracy: 0.7685 - top_k_categorical_accuracy: 0.9370 - val_loss: 1.3296 - val_accuracy: 0.6469 - val_top_k_categorical_accuracy: 0.8844\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.41176 to 1.32957, saving model to data/checkpoints/inception.005-1.33.hdf5\n",
            "Epoch 6/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.7714 - top_k_categorical_accuracy: 0.9368WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 760ms/step - loss: 0.8726 - accuracy: 0.7715 - top_k_categorical_accuracy: 0.9368 - val_loss: 1.5658 - val_accuracy: 0.6062 - val_top_k_categorical_accuracy: 0.8250\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.32957\n",
            "Epoch 7/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.8001 - top_k_categorical_accuracy: 0.9400WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 83s 774ms/step - loss: 0.7748 - accuracy: 0.8002 - top_k_categorical_accuracy: 0.9401 - val_loss: 1.3534 - val_accuracy: 0.6125 - val_top_k_categorical_accuracy: 0.8813\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.32957\n",
            "Epoch 8/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.8265 - top_k_categorical_accuracy: 0.9596WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 84s 782ms/step - loss: 0.6670 - accuracy: 0.8265 - top_k_categorical_accuracy: 0.9595 - val_loss: 1.3565 - val_accuracy: 0.6562 - val_top_k_categorical_accuracy: 0.8656\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.32957\n",
            "Epoch 9/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7136 - accuracy: 0.8112 - top_k_categorical_accuracy: 0.9492WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 83s 776ms/step - loss: 0.7134 - accuracy: 0.8113 - top_k_categorical_accuracy: 0.9492 - val_loss: 1.3562 - val_accuracy: 0.6313 - val_top_k_categorical_accuracy: 0.8750\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.32957\n",
            "Epoch 10/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7240 - accuracy: 0.8237 - top_k_categorical_accuracy: 0.9434WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 82s 767ms/step - loss: 0.7236 - accuracy: 0.8238 - top_k_categorical_accuracy: 0.9435 - val_loss: 1.4195 - val_accuracy: 0.6344 - val_top_k_categorical_accuracy: 0.8469\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.32957\n",
            "Epoch 11/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.8363 - top_k_categorical_accuracy: 0.9614WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 81s 762ms/step - loss: 0.6313 - accuracy: 0.8362 - top_k_categorical_accuracy: 0.9614 - val_loss: 1.1357 - val_accuracy: 0.6969 - val_top_k_categorical_accuracy: 0.8875\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.32957 to 1.13570, saving model to data/checkpoints/inception.011-1.14.hdf5\n",
            "Epoch 12/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.8375 - top_k_categorical_accuracy: 0.9662WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 81s 771ms/step - loss: 0.6043 - accuracy: 0.8375 - top_k_categorical_accuracy: 0.9662 - val_loss: 1.1471 - val_accuracy: 0.7156 - val_top_k_categorical_accuracy: 0.8781\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.13570\n",
            "Epoch 13/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6513 - accuracy: 0.8279 - top_k_categorical_accuracy: 0.9589WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 84s 780ms/step - loss: 0.6514 - accuracy: 0.8279 - top_k_categorical_accuracy: 0.9590 - val_loss: 1.1092 - val_accuracy: 0.7031 - val_top_k_categorical_accuracy: 0.9031\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.13570 to 1.10920, saving model to data/checkpoints/inception.013-1.11.hdf5\n",
            "Epoch 14/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.8341 - top_k_categorical_accuracy: 0.9669WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 81s 774ms/step - loss: 0.5960 - accuracy: 0.8341 - top_k_categorical_accuracy: 0.9669 - val_loss: 1.2776 - val_accuracy: 0.6469 - val_top_k_categorical_accuracy: 0.8687\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.10920\n",
            "Epoch 15/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.8370 - top_k_categorical_accuracy: 0.9681WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 83s 775ms/step - loss: 0.5913 - accuracy: 0.8370 - top_k_categorical_accuracy: 0.9680 - val_loss: 1.4537 - val_accuracy: 0.6219 - val_top_k_categorical_accuracy: 0.8438\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.10920\n",
            "Epoch 16/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.8506 - top_k_categorical_accuracy: 0.9735WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 82s 763ms/step - loss: 0.5518 - accuracy: 0.8506 - top_k_categorical_accuracy: 0.9735 - val_loss: 1.2491 - val_accuracy: 0.6781 - val_top_k_categorical_accuracy: 0.8813\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.10920\n",
            "Epoch 17/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.8370 - top_k_categorical_accuracy: 0.9655WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 80s 754ms/step - loss: 0.5934 - accuracy: 0.8371 - top_k_categorical_accuracy: 0.9655 - val_loss: 1.1677 - val_accuracy: 0.6562 - val_top_k_categorical_accuracy: 0.8969\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.10920\n",
            "Epoch 18/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.8599 - top_k_categorical_accuracy: 0.9616WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 81s 749ms/step - loss: 0.5524 - accuracy: 0.8598 - top_k_categorical_accuracy: 0.9616 - val_loss: 1.3621 - val_accuracy: 0.6281 - val_top_k_categorical_accuracy: 0.8625\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.10920\n",
            "Epoch 19/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8606 - top_k_categorical_accuracy: 0.9698WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 82s 766ms/step - loss: 0.5448 - accuracy: 0.8606 - top_k_categorical_accuracy: 0.9698 - val_loss: 1.2140 - val_accuracy: 0.6844 - val_top_k_categorical_accuracy: 0.8906\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.10920\n",
            "Epoch 20/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8598 - top_k_categorical_accuracy: 0.9718WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 83s 780ms/step - loss: 0.5248 - accuracy: 0.8598 - top_k_categorical_accuracy: 0.9718 - val_loss: 1.2014 - val_accuracy: 0.6844 - val_top_k_categorical_accuracy: 0.8938\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.10920\n",
            "Epoch 21/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8708 - top_k_categorical_accuracy: 0.9753WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 83s 779ms/step - loss: 0.5124 - accuracy: 0.8708 - top_k_categorical_accuracy: 0.9754 - val_loss: 1.1881 - val_accuracy: 0.6406 - val_top_k_categorical_accuracy: 0.8656\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.10920\n",
            "Epoch 22/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5279 - accuracy: 0.8613 - top_k_categorical_accuracy: 0.9664WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 83s 774ms/step - loss: 0.5277 - accuracy: 0.8613 - top_k_categorical_accuracy: 0.9664 - val_loss: 1.2066 - val_accuracy: 0.6812 - val_top_k_categorical_accuracy: 0.8781\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.10920\n",
            "Epoch 23/1000\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.8700 - top_k_categorical_accuracy: 0.9753WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "100/100 [==============================] - 82s 767ms/step - loss: 0.4838 - accuracy: 0.8699 - top_k_categorical_accuracy: 0.9753 - val_loss: 1.1258 - val_accuracy: 0.6750 - val_top_k_categorical_accuracy: 0.9000\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.10920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_TViEDKnD1s",
        "outputId": "7a17295e-1bc7-484b-bdc3-5fa833acbc3e"
      },
      "source": [
        "!ls data/logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cnn-training-1612368312.2867029.log  train  validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gdEhmnepcBl",
        "outputId": "819b035c-5499-4a6f-e006-da59aea4ab91"
      },
      "source": [
        "!cd data && zip logger6-cnn.zip checkpoints/inception.013-1.11.hdf5\n",
        "!cd data && zip -r logger6-cnn.zip logs\n",
        "!rsync data/logger6-cnn.zip drive/MyDrive/write_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: checkpoints/inception.013-1.11.hdf5 (deflated 10%)\n",
            "  adding: logs/ (stored 0%)\n",
            "  adding: logs/cnn-training-1612368312.2867029.log (deflated 61%)\n",
            "  adding: logs/validation/ (stored 0%)\n",
            "  adding: logs/validation/events.out.tfevents.1612369317.04193ea7c4ae.62.25098.v2 (deflated 68%)\n",
            "  adding: logs/train/ (stored 0%)\n",
            "  adding: logs/train/plugins/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/ (stored 0%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/04193ea7c4ae.trace.json.gz (deflated 3%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/04193ea7c4ae.input_pipeline.pb (deflated 56%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/04193ea7c4ae.xplane.pb (deflated 80%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/04193ea7c4ae.memory_profile.json.gz (deflated 0%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/04193ea7c4ae.tensorflow_stats.pb (deflated 71%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/04193ea7c4ae.kernel_stats.pb (deflated 95%)\n",
            "  adding: logs/train/plugins/profile/2021_02_03_16_20_48/04193ea7c4ae.overview_page.pb (deflated 57%)\n",
            "  adding: logs/train/events.out.tfevents.1612369248.04193ea7c4ae.profile-empty (deflated 10%)\n",
            "  adding: logs/train/events.out.tfevents.1612369237.04193ea7c4ae.62.16767.v2 (deflated 94%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v-k8cz9qb8W"
      },
      "source": [
        "import sys\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_log = '/content/data/logs/cnn-training-1609571960.010799.log'\n",
        "\n",
        "validation_accuracies = []\n",
        "validation_loss = []\n",
        "training_accuracies = []\n",
        "training_loss = []\n",
        "validation_top_5_acc = []\n",
        "training_top_5_acc = []\n",
        "\n",
        "with open(training_log) as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    next(reader, None)  # skip the header\n",
        "    for epoch,acc,loss,top_k_categorical_accuracy,val_acc,val_loss,val_top_k_categorical_accuracy in reader:\n",
        "        validation_accuracies.append(float(val_acc))\n",
        "        validation_loss.append(float(val_loss))\n",
        "        validation_top_5_acc.append(float(val_top_k_categorical_accuracy))\n",
        "        training_loss.append(float(loss))\n",
        "        training_accuracies.append(float(acc))\n",
        "        training_top_5_acc.append(float(top_k_categorical_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw2OQmn8sMrn"
      },
      "source": [
        "plt.subplot(3, 1, 1)   \n",
        "plt.plot(validation_loss, label='validation loss')\n",
        "plt.plot(training_loss, label='training loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.xlim((0, len(training_loss)))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('cnn-metrics-plot-loss.png')\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(validation_accuracies, label='validation acc')\n",
        "plt.plot(training_accuracies, label='training acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlim((0, len(training_accuracies)))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('cnn-metrics-plot-acc.png')\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(validation_top_5_acc, label='validation top-5 acc')\n",
        "plt.plot(training_top_5_acc, label='training top-5 acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('top 5 categorical accuracy')\n",
        "plt.xlim((0, len(training_accuracies)))\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('cnn-metrics-plot-top5.png')\n",
        "plt.title('Top 5 Categorical Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHu0TLXtjvx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAMya8HxtkGY"
      },
      "source": [
        "# function ConnectButton(){\n",
        "#     console.log(\"Connect pushed\"); \n",
        "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "# }\n",
        "# interval = setInterval(ConnectButton,60000);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}